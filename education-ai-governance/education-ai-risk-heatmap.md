# Education AI Risk Heatmap (Executive View)

This artifact prioritizes AI risks in education environments using an
Impact × Likelihood lens, aligned to FERPA/COPPA expectations and
Responsible AI governance principles.

## High Impact / High Likelihood
- Biased grading or assessment outcomes
- Disparate impact in placement or intervention models
- Unauthorized use of student data

## High Impact / Medium Likelihood
- Opaque AI recommendations without explanation
- Inadequate appeal or override mechanisms

## Medium Impact / High Likelihood
- Model drift affecting accuracy over time
- Vendor opacity and insufficient audit access

## Low Impact / Low Likelihood
- Non-material automation errors (monitored)

---

## 90-Day AI Governance Plan (Education)

### Days 1–30: Discover & Assess
- Inventory AI systems used in instruction and administration
- Assign accountability and data stewardship roles
- Conduct privacy and bias risk assessments

### Days 31–60: Design & Control
- Implement human-in-the-loop decision checkpoints
- Define transparency and disclosure standards
- Establish bias mitigation and documentation practices

### Days 61–90: Operate & Monitor
- Stand up monitoring and audit logging
- Formalize appeal and override processes
- Deliver executive reporting on AI risk and controls

Outcome: Audit-ready, student-centered, and compliant AI use in education.
