# Cross-Sector AI Risk Heatmap (Executive View)

This artifact synthesizes AI risk across multiple regulated and
public-interest domains using an Impact Ã— Likelihood framework.

The purpose is to help executives prioritize governance attention,
controls, and oversight across different AI deployment contexts.

---

## High Impact / High Likelihood

### Real Estate
- Discriminatory pricing or valuation outcomes
- Fair housing exposure due to opaque AI recommendations

### Education
- Biased grading, assessment, or placement decisions
- Unauthorized use or inference from student data

### Regulated Retail / Cannabis
- Inaccurate or biased ID and age verification
- Disparate enforcement or access decisions

---

## High Impact / Medium Likelihood

- Opaque AI decision logic without explanation
- Vendor-controlled models with limited auditability
- Lack of meaningful appeal or override mechanisms

---

## Medium Impact / High Likelihood

- Model drift degrading accuracy over time
- Data quality issues affecting recommendations
- Over-reliance on AI without human validation

---

## Low Impact / Low Likelihood

- Non-material automation errors
- Forecasting or optimization inaccuracies
- Administrative efficiency use cases (monitored)

---

## Governance Implication

While AI use cases differ by sector, **risk patterns converge** around:
- Bias and disparate impact
- Transparency and explainability
- Human accountability
- Vendor and model risk

This reinforces the need for a **shared governance core**
with **sector-specific controls** layered on top.
